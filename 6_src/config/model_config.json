{
  "carma": {
    "p": 3,
    "q": 0,
    "nwalkers": 1000
  },
  "vanilla_lstm": {
    "window_len": 10,
    "hidden_dim": 4,
    "epochs": 100,
    "batch_size": 32
  },
  "attention_lstm":{
    "window_len": 10,
    "hidden_dim": 0.5,
    "epochs": 100,
    "batch_size": 32
  },

  "dnn": {
    "n_layers": 5,
    "n_units": 800,
    "dropout": 0.05,
    "tau": 0.75,
    "epochs": 5120,
    "walkers": 500,
    "batch_size": 128,
    "lengthscale": 1e-2
  }
}